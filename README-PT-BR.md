[![English](https://img.shields.io/badge/English-Inactive-lightgrey?style=flat-square)](README.md) [![Ğ ÑƒÑÑĞºĞ¸Ğ¹](https://img.shields.io/badge/Ğ ÑƒÑÑĞºĞ¸Ğ¹-Inactive-lightgrey?style=flat-square)](README-RU.md) [![PortuguÃªs](https://img.shields.io/badge/PortuguÃªs-Active-success?style=flat-square)](README-PT-BR.md)

<!-- Logo do Projeto -->
<p align="center">
  <img src=".github/assets/logo.svg" alt="Logo Oxide Lab" width="512" />
</p>

> **Chat de IA privado, poderoso e fÃ¡cil de usar diretamente no seu computador**

![Oxide Lab](https://img.shields.io/badge/Status-Active-brightgreen) ![Platform](https://img.shields.io/badge/Platform-Windows-blue) ![License](https://img.shields.io/badge/License-MIT-yellow) ![Legal](https://img.shields.io/badge/Legal-Compliant-green)

![GitHub Stars](https://img.shields.io/github/stars/FerrisMind/Oxide-Lab?style=social) [![Awesome Tauri](https://awesome.re/mentioned-badge.svg)](https://github.com/tauri-apps/awesome-tauri) [![Awesome Svelte](https://awesome.re/mentioned-badge.svg)](https://github.com/TheComputerM/awesome-svelte)

---

## ğŸ“š Ãndice

- [O que Ã© isso?](#-o-que-Ã©-isso)
- [Para quem Ã© este aplicativo?](#-para-quem-Ã©-este-aplicativo)
- [Recursos Principais](#-recursos-principais)
- [Reconhecimento](#ï¸-reconhecimento)
- [InstalaÃ§Ã£o e ConfiguraÃ§Ã£o](#ï¸-instalaÃ§Ã£o-e-configuraÃ§Ã£o)
- [Como ComeÃ§ar a Usar](#-como-comeÃ§ar-a-usar)
- [Recursos da Interface](#-recursos-da-interface)
- [Privacidade e SeguranÃ§a](#-privacidade-e-seguranÃ§a)
- [Dicas e RecomendaÃ§Ãµes](#-dicas-e-recomendaÃ§Ãµes)
- [Requisitos do Sistema e LimitaÃ§Ãµes](#-requisitos-do-sistema-e-limitaÃ§Ãµes)
- [Apoiar o Projeto](#-apoiar-o-projeto)
- [Agradecimentos](#-agradecimentos)

---

## âœ¨ O que Ã© isso?

**Oxide Lab** Ã© um aplicativo desktop moderno para comunicaÃ§Ã£o com modelos de IA que funciona completamente localmente no seu computador. Sem assinaturas, sem envio de dados para a internet â€” apenas vocÃª e seu assistente de IA pessoal.

### ğŸ¯ Para quem Ã© este aplicativo?

- **Entusiastas de IA** â€” querem experimentar modelos localmente
- **Privacidade importa** â€” seus dados ficam apenas com vocÃª
- **Pesquisadores** â€” precisam de controle sobre parÃ¢metros de geraÃ§Ã£o
- **Mentes criativas** â€” usam IA para escrita, brainstorming e inspiraÃ§Ã£o

---

## ğŸš€ Recursos Principais

### ğŸ’¬ **Interface de Chat Inteligente**

- Design moderno e intuitivo
- Respostas em streaming em tempo real
- Suporte para formataÃ§Ã£o de texto e cÃ³digo

### ğŸ§  **Modo de Pensamento**

- Ative o recurso **"Pensamento"** e observe a IA pensar
- Veja o processo de anÃ¡lise antes da resposta final
- SoluÃ§Ãµes de maior qualidade e mais pensadas para tarefas complexas

### âš™ï¸ **ConfiguraÃ§Ãµes FlexÃ­veis**

- **Temperatura** â€” controle a criatividade da resposta
- **Top-K, Top-P, Min-P** â€” ajuste fino do estilo de geraÃ§Ã£o
- **Penalidade de RepetiÃ§Ã£o** â€” evite repetiÃ§Ãµes
- **Comprimento do Contexto** â€” depende do modelo e dos recursos do dispositivo

### ğŸ”§ **ConfiguraÃ§Ã£o FÃ¡cil**

- Suporte para modelos Qwen3 locais no formato GGUF (outros modelos â€” em planejamento)
- Gerenciamento inteligente de memÃ³ria

---

## ğŸ–ï¸ Reconhecimento

Oxide Lab foi reconhecido pela comunidade por sua qualidade e inovaÃ§Ã£o:

- â­ **100+ estrelas no GitHub** nos primeiros 3-4 meses de desenvolvimento solo
- ğŸ† **Destaque em [Awesome Tauri](https://github.com/tauri-apps/awesome-tauri)** â€” lista curada de aplicativos Tauri de qualidade
- ğŸ† **Destaque em [Awesome Svelte](https://github.com/TheComputerM/awesome-svelte)** â€” lista curada de projetos Svelte de qualidade

---

## ğŸ› ï¸ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### PrÃ©-requisitos

Antes de instalar o Oxide Lab, certifique-se de ter o seguinte instalado:

- **Node.js** (versÃ£o 18 ou superior) - [Download](https://nodejs.org/)
- **Rust** (Ãºltima versÃ£o estÃ¡vel) - [Instalar](https://rustup.rs/)
- **Git** - [Download](https://git-scm.com/)

#### Para AceleraÃ§Ã£o GPU (Opcional mas Recomendado)

- **CUDA 12.0+** para GPUs NVIDIA (Windows/Linux)

### Passos de InstalaÃ§Ã£o

1. **Clone o repositÃ³rio:**

   ```bash
   git clone https://github.com/FerrisMind/Oxide-Lab.git
   cd Oxide-Lab
   ```

2. **Instale as dependÃªncias:**

   ```bash
   npm install
   ```

3. **Execute em modo de desenvolvimento:**

   ```bash
   # Para modo apenas CPU
   npm run tauri:dev:cpu

   # Para modo GPU CUDA (se CUDA estiver disponÃ­vel)
   npm run tauri:dev:cuda
   ```

4. **Compile para produÃ§Ã£o:**

   ```bash
   # CompilaÃ§Ã£o apenas CPU
   npm run tauri:build:cpu

   # CompilaÃ§Ã£o CUDA
   npm run tauri:build:cuda
   ```

### Requisitos do Sistema

- **SO:** Windows 10/11, Linux, macOS
- **RAM:** MÃ­nimo 4GB, Recomendado 8GB+
- **Armazenamento:** 500MB para aplicativo + tamanho do modelo
- **GPU:** Opcional, mas recomendado para melhor desempenho

### SoluÃ§Ã£o de Problemas

- Se encontrar problemas de compilaÃ§Ã£o, certifique-se de que Rust e Node.js estÃ£o instalados corretamente
- Para suporte GPU, verifique a instalaÃ§Ã£o do CUDA
- Verifique a pÃ¡gina [Issues](https://github.com/FerrisMind/Oxide-Lab/issues) para problemas comuns

---

## ğŸ“– Como ComeÃ§ar a Usar

### 1ï¸âƒ£ **Obtenha o Modelo**

Baixe um modelo no formato `.gguf` e o arquivo `tokenizer.json`:

- **Modelos recomendados:** Qwen3 4B (e outras variantes Qwen3 em GGUF)
- **Onde baixar:** [Hugging Face](https://huggingface.co/collections/Qwen/qwen3-67dd247413f0e2e4f653967f), repositÃ³rios oficiais de modelos

### 2ï¸âƒ£ **Carregue no Aplicativo**

1. Abra o Oxide Lab
2. Clique em **"Selecionar Arquivo do Modelo"** e especifique o caminho para o arquivo `.gguf`
3. Opcionalmente configure os parÃ¢metros de inferÃªncia
4. Clique em **"Carregar"**

### 3ï¸âƒ£ **Comece a Conversar**

- Digite sua pergunta ou solicitaÃ§Ã£o
- Ative **"Pensamento"** para respostas mais profundas
- Ajuste os parÃ¢metros de geraÃ§Ã£o ao seu gosto
- Aproveite a conversa com sua IA pessoal!

---

## ğŸ¨ Recursos da Interface

### ğŸ“Š **Indicadores Informativos**

- Progresso de carregamento do modelo com estÃ¡gios detalhados
- Indicadores de status de geraÃ§Ã£o
- ExibiÃ§Ã£o visual do pensamento da IA

<p align="center">
  <img src=".github/assets/screenshots/chat-dark.png" alt="Interface de Chat Oxide Lab (Escuro)" width="720" />
</p>

### âš¡ **AÃ§Ãµes RÃ¡pidas**

- Cancele o carregamento do modelo com um clique
- Pare a geraÃ§Ã£o a qualquer momento
- MudanÃ§as rÃ¡pidas de parÃ¢metros sem recarregar

---

## ğŸ›¡ï¸ Privacidade e SeguranÃ§a

### ğŸ”’ **100% Local**

- Todos os cÃ¡lculos acontecem no seu computador
- Sem solicitaÃ§Ãµes externas ou envio de dados
- Controle total sobre suas informaÃ§Ãµes

### ğŸ’¾ **Gerenciamento de Dados**

- Conversas armazenadas apenas na sessÃ£o do aplicativo
- Modelos permanecem no seu disco
- Sem coleta oculta de dados

---

## ğŸ’¡ Dicas e RecomendaÃ§Ãµes

### ğŸ¯ **Para melhores resultados:**

- Use o modo de pensamento para tarefas complexas
- O aplicativo jÃ¡ possui as melhores configuraÃ§Ãµes integradas com base nas recomendaÃ§Ãµes do fabricante do modelo Qwen3. Basta ativar e usar!
- O aplicativo tambÃ©m suporta alteraÃ§Ã£o das configuraÃ§Ãµes padrÃ£o. Experimente com temperatura: 0.7-1.0 para criatividade, 0.1-0.3 para precisÃ£o
- Aumente o contexto para trabalhar com documentos longos

### âš¡ **OtimizaÃ§Ã£o de desempenho:**

- Suporta CPU e GPU (CUDA)

### ğŸ¨ **Uso criativo:**

- Ative o pensamento para anÃ¡lise de texto e resoluÃ§Ã£o de problemas
- Experimente alta temperatura para escrita criativa
- Use contexto longo para trabalhar com documentos grandes

---

## ğŸ–¥ï¸ Requisitos do Sistema e LimitaÃ§Ãµes

### Plataformas Suportadas

- Windows 10/11 â€” suporte completo
- Linux e macOS â€” em fase de planejamento (ainda nÃ£o suportados)

### Modelos

- Suportados: Qwen3 no formato GGUF (mono-arquitetura)
- Importante: compatibilidade com outros modelos ainda nÃ£o Ã© garantida

### Requisitos MÃ­nimos de Hardware

Os menores modelos Qwen3 (0.6B e 1.7B) funcionam com velocidade e qualidade aceitÃ¡veis mesmo em dispositivos com CPU de 2 nÃºcleos e 4 GB de RAM. O modelo 4B tambÃ©m funciona neste aplicativo com tais dispositivos, mas o desempenho Ã© muitas vezes menor e requer mais memÃ³ria, o que Ã© difÃ­cil de alcanÃ§ar, por exemplo, com LM Studio sem perda significativa de qualidade.

### Contexto e Desempenho

- O comprimento efetivo do contexto depende de: modelo selecionado, RAM disponÃ­vel
- O comprimento do contexto praticamente alcanÃ§Ã¡vel pode ser menor do que o teoricamente declarado pelo modelo
- Quanto maior o contexto, maiores os requisitos de memÃ³ria e menor a velocidade de geraÃ§Ã£o

---

## ğŸŒŸ Apoiar o Projeto

Se o Oxide Lab foi Ãºtil para vocÃª:

- â­ DÃª uma estrela ao projeto
- ğŸ› Reporte bugs
- ğŸ’¡ Sugira novos recursos
- ğŸ¤ Compartilhe com amigos

---

## ğŸ™ Agradecimentos

Oxide Lab Ã© construÃ­do com a ajuda de tecnologias incrÃ­veis de cÃ³digo aberto:

- **[Rust](https://www.rust-lang.org/)** - Linguagem de programaÃ§Ã£o de sistemas que garante seguranÃ§a de memÃ³ria e desempenho
- **[Tauri](https://tauri.app/)** - Framework para construir aplicativos desktop rÃ¡pidos e seguros
- **[Candle](https://github.com/huggingface/candle)** - Framework ML minimalista para Rust
- **[Phosphor Icons](https://phosphoricons.com/)** - Conjunto de Ã­cones bonito e consistente

### TraduÃ§Ã£o

- **TraduÃ§Ã£o para portuguÃªs brasileiro:** Talita Maia Sousa

---

> **Feito com â¤ï¸ para a comunidade de entusiastas de IA**  
> _Liberdade, privacidade e controle sobre inteligÃªncia artificial_


