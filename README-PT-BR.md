[![English](https://img.shields.io/badge/English-Inactive-lightgrey)](README.md) [![–†—É—Å—Å–∫–∏–π](https://img.shields.io/badge/–†—É—Å—Å–∫–∏–π-Inactive-lightgrey)](README-RU.md) [![Portugu√™s](https://img.shields.io/badge/Portugu√™s-Active-success)](README-PT-BR.md)

<br />

<!-- Logo do Projeto -->
<p align="center">
  <img src="https://raw.githubusercontent.com/FerrisMind/Oxide-Lab/main/.github/assets/logo.svg" alt="Logo Oxide Lab" width="512" />
</p>

<br />

> **Chat de IA privado, poderoso e f√°cil de usar diretamente no seu computador**

![Oxide Lab](https://img.shields.io/badge/Status-Active-brightgreen) ![Platform](https://img.shields.io/badge/Platform-Windows-blue) ![License](https://img.shields.io/badge/License-Apache%202.0-blue)

![GitHub Stars](https://img.shields.io/github/stars/FerrisMind/Oxide-Lab?style=social) [![Awesome Tauri](https://awesome.re/mentioned-badge.svg)](https://github.com/tauri-apps/awesome-tauri) [![Awesome Svelte](https://awesome.re/mentioned-badge.svg)](https://github.com/TheComputerM/awesome-svelte)


<p align="center">
  <img src="https://raw.githubusercontent.com/FerrisMind/Oxide-Lab/main/.github/assets/screenshots/chat-dark.png" alt="Oxide Lab Chat UI (Dark)" width="900" />
</p>

---

## üìö √çndice

- [O que √© isso?](#-o-que-√©-isso)
- [Para quem √© este aplicativo?](#-para-quem-√©-este-aplicativo)
- [Recursos Principais](#-recursos-principais)
- [Reconhecimento](#Ô∏è-reconhecimento)
- [Instala√ß√£o e Configura√ß√£o](#Ô∏è-instala√ß√£o-e-configura√ß√£o)
- [Como Come√ßar a Usar](#-como-come√ßar-a-usar)
- [Recursos da Interface](#-recursos-da-interface)
- [Privacidade e Seguran√ßa](#-privacidade-e-seguran√ßa)
- [Dicas e Recomenda√ß√µes](#-dicas-e-recomenda√ß√µes)
- [Requisitos do Sistema e Limita√ß√µes](#-requisitos-do-sistema-e-limita√ß√µes)
- [Apoiar o Projeto](#-apoiar-o-projeto)
- [Agradecimentos](#-agradecimentos)

---

## ‚ú® O que √© isso?

**Oxide Lab** √© um aplicativo desktop moderno para comunica√ß√£o com modelos de IA que funciona completamente localmente no seu computador. Sem assinaturas, sem envio de dados para a internet ‚Äî apenas voc√™ e seu assistente de IA pessoal.

### üéØ Para quem √© este aplicativo?

- **Entusiastas de IA** ‚Äî querem experimentar modelos localmente
- **Privacidade importa** ‚Äî seus dados ficam apenas com voc√™
- **Pesquisadores** ‚Äî precisam de controle sobre par√¢metros de gera√ß√£o
- **Mentes criativas** ‚Äî usam IA para escrita, brainstorming e inspira√ß√£o

---

## üöÄ Recursos Principais

### üí¨ **Interface de Chat Inteligente**

- Design moderno e intuitivo
- Respostas em streaming em tempo real
- Suporte para formata√ß√£o de texto e c√≥digo

### üß† **Modo de Pensamento**

- Ative o recurso **"Pensamento"** e observe a IA pensar
- Veja o processo de an√°lise antes da resposta final
- Solu√ß√µes de maior qualidade e mais pensadas para tarefas complexas

### ‚öôÔ∏è **Configura√ß√µes Flex√≠veis**

- **Temperatura** ‚Äî controle a criatividade da resposta
- **Top-K, Top-P, Min-P** ‚Äî ajuste fino do estilo de gera√ß√£o
- **Penalidade de Repeti√ß√£o** ‚Äî evite repeti√ß√µes
- **Comprimento do Contexto** ‚Äî depende do modelo e dos recursos do dispositivo

### üîß **Configura√ß√£o F√°cil**

- Suporte para modelos Qwen3 locais no formato GGUF (outros modelos ‚Äî em planejamento)
- Gerenciamento inteligente de mem√≥ria

---

## üéñÔ∏è Reconhecimento

Oxide Lab foi reconhecido pela comunidade por sua qualidade e inova√ß√£o:

- üèÜ **Destaque em [Awesome Tauri](https://github.com/tauri-apps/awesome-tauri)** ‚Äî lista curada de aplicativos Tauri de qualidade
- üèÜ **Destaque em [Awesome Svelte](https://github.com/TheComputerM/awesome-svelte)** ‚Äî lista curada de projetos Svelte de qualidade

---

## üõ†Ô∏è Instala√ß√£o e Configura√ß√£o

### Pr√©-requisitos

Antes de instalar o Oxide Lab, certifique-se de ter o seguinte instalado:

- **Node.js** (vers√£o 18 ou superior) - [Download](https://nodejs.org/)
- **Rust** (√∫ltima vers√£o est√°vel) - [Instalar](https://rustup.rs/)
- **Git** - [Download](https://git-scm.com/)

#### Para Acelera√ß√£o GPU (Opcional mas Recomendado)

- **CUDA 12.0+** para GPUs NVIDIA (Windows/Linux)

### Passos de Instala√ß√£o

1. **Clone o reposit√≥rio:**

   ```bash
   git clone https://github.com/FerrisMind/Oxide-Lab.git
   cd Oxide-Lab
   ```

2. **Instale as depend√™ncias:**

   ```bash
   npm install
   ```

3. **Execute em modo de desenvolvimento:**

   ```bash
   # Para modo apenas CPU
   npm run tauri:dev:cpu

   # Para modo GPU CUDA (se CUDA estiver dispon√≠vel)
   npm run tauri:dev:cuda
   ```

4. **Compile para produ√ß√£o:**

   ```bash
   # Compila√ß√£o apenas CPU
   npm run tauri:build:cpu

   # Compila√ß√£o CUDA
   npm run tauri:build:cuda
   ```

### Requisitos do Sistema

- **SO:** Windows 10/11, Linux, macOS
- **RAM:** M√≠nimo 4GB, Recomendado 8GB+
- **Armazenamento:** 500MB para aplicativo + tamanho do modelo
- **GPU:** Opcional, mas recomendado para melhor desempenho

### Solu√ß√£o de Problemas

- Se encontrar problemas de compila√ß√£o, certifique-se de que Rust e Node.js est√£o instalados corretamente
- Para suporte GPU, verifique a instala√ß√£o do CUDA
- Verifique a p√°gina [Issues](https://github.com/FerrisMind/Oxide-Lab/issues) para problemas comuns

---

## üìñ Como Come√ßar a Usar

### 1Ô∏è‚É£ **Obtenha o Modelo**

Baixe um modelo no formato `.gguf` e o arquivo `tokenizer.json`:

- **Modelos recomendados:** Qwen3 4B (e outras variantes Qwen3 em GGUF)
- **Onde baixar:** [Hugging Face](https://huggingface.co/collections/Qwen/qwen3-67dd247413f0e2e4f653967f), reposit√≥rios oficiais de modelos

### 2Ô∏è‚É£ **Carregue no Aplicativo**

1. Abra o Oxide Lab
2. Clique em **"Selecionar Arquivo do Modelo"** e especifique o caminho para o arquivo `.gguf`
3. Opcionalmente configure os par√¢metros de infer√™ncia
4. Clique em **"Carregar"**

### 3Ô∏è‚É£ **Comece a Conversar**

- Digite sua pergunta ou solicita√ß√£o
- Ative **"Pensamento"** para respostas mais profundas
- Ajuste os par√¢metros de gera√ß√£o ao seu gosto
- Aproveite a conversa com sua IA pessoal!

---

## üé® Recursos da Interface

### üìä **Indicadores Informativos**

- Progresso de carregamento do modelo com est√°gios detalhados
- Indicadores de status de gera√ß√£o
- Exibi√ß√£o visual do pensamento da IA

### ‚ö° **A√ß√µes R√°pidas**

- Cancele o carregamento do modelo com um clique
- Pare a gera√ß√£o a qualquer momento
- Mudan√ßas r√°pidas de par√¢metros sem recarregar

---

## üõ°Ô∏è Privacidade e Seguran√ßa

### üîí **100% Local**

- Todos os c√°lculos acontecem no seu computador
- Sem solicita√ß√µes externas ou envio de dados
- Controle total sobre suas informa√ß√µes

### üíæ **Gerenciamento de Dados**

- Conversas armazenadas apenas na sess√£o do aplicativo
- Modelos permanecem no seu disco
- Sem coleta oculta de dados

---

## üí° Dicas e Recomenda√ß√µes

### üéØ **Para melhores resultados:**

- Use o modo de pensamento para tarefas complexas
- O aplicativo j√° possui as melhores configura√ß√µes integradas com base nas recomenda√ß√µes do fabricante do modelo Qwen3. Basta ativar e usar!
- O aplicativo tamb√©m suporta altera√ß√£o das configura√ß√µes padr√£o. Experimente com temperatura: 0.7-1.0 para criatividade, 0.1-0.3 para precis√£o
- Aumente o contexto para trabalhar com documentos longos

### ‚ö° **Otimiza√ß√£o de desempenho:**

- Suporta CPU e GPU (CUDA)

### üé® **Uso criativo:**

- Ative o pensamento para an√°lise de texto e resolu√ß√£o de problemas
- Experimente alta temperatura para escrita criativa
- Use contexto longo para trabalhar com documentos grandes

---

## üñ•Ô∏è Requisitos do Sistema e Limita√ß√µes

### Plataformas Suportadas

- Windows 10/11 ‚Äî suporte completo
- Linux e macOS ‚Äî em fase de planejamento (ainda n√£o suportados)

### Modelos

- Suportados: Qwen3 no formato GGUF (mono-arquitetura)
- Importante: compatibilidade com outros modelos ainda n√£o √© garantida

### Requisitos M√≠nimos de Hardware

Os menores modelos Qwen3 (0.6B e 1.7B) funcionam com velocidade e qualidade aceit√°veis mesmo em dispositivos com CPU de 2 n√∫cleos e 4 GB de RAM. O modelo 4B tamb√©m funciona neste aplicativo com tais dispositivos, mas o desempenho √© muitas vezes menor e requer mais mem√≥ria, o que √© dif√≠cil de alcan√ßar, por exemplo, com LM Studio sem perda significativa de qualidade.

### Contexto e Desempenho

- O comprimento efetivo do contexto depende de: modelo selecionado, RAM dispon√≠vel
- O comprimento do contexto praticamente alcan√ß√°vel pode ser menor do que o teoricamente declarado pelo modelo
- Quanto maior o contexto, maiores os requisitos de mem√≥ria e menor a velocidade de gera√ß√£o

---

## üåü Apoiar o Projeto

Se o Oxide Lab foi √∫til para voc√™:

- ‚≠ê D√™ uma estrela ao projeto
- üêõ Reporte bugs
- üí° Sugira novos recursos
- ü§ù Compartilhe com amigos

---

## üôè Agradecimentos

Oxide Lab √© constru√≠do com a ajuda de tecnologias incr√≠veis de c√≥digo aberto:

- **[Rust](https://www.rust-lang.org/)** - Linguagem de programa√ß√£o de sistemas que garante seguran√ßa de mem√≥ria e desempenho
- **[Tauri](https://tauri.app/)** - Framework para construir aplicativos desktop r√°pidos e seguros
- **[Candle](https://github.com/huggingface/candle)** - Framework ML minimalista para Rust
- **[Phosphor Icons](https://phosphoricons.com/)** - Conjunto de √≠cones bonito e consistente

### Tradu√ß√£o

- **Tradu√ß√£o para portugu√™s brasileiro:** Talita Maia Sousa

---

> **Feito com ‚ù§Ô∏è para a comunidade de entusiastas de IA**  
> _Liberdade, privacidade e controle sobre intelig√™ncia artificial_
