Цель: минимизировать архитектурно-зависимый код и упростить добавление новых архитектур (GGUF и float/safetensors) через единые абстракции загрузки, инициализации, токенизации и генерации.

Приоритетные группы: P0 (высокий эффект, низкие риски/затраты) → P1 → P2.

P0 — Быстрые и наиболее эффективные

- Авто-выбор устройства CUDA → Metal → CPU
  - Назначение: автоматически выбирать лучшее доступное устройство, как в примерах Candle.
  - Влияние: более предсказуемая производительность без лишних настроек; единая политика по умолчанию.
  - Затраты: низкие (точечные изменения).
  - Где: `src-tauri/src/core/device.rs` (`select_device`), при необходимости сообщения в `src-tauri/src/api/device.rs`.
  - Статус: РЕАЛИЗОВАНО ✓ (улучшенная версия с корректной runtime-детекцией)

- Универсальный загрузчик весов и VarBuilder (Hub/локально)
  - Назначение: вынести в модуль общую логику: поиск `model.safetensors.index.json`, сбор списка шардов/файлов, построение `VarBuilder` с единой политикой `dtype`.
  - Влияние: исключение дублирования, единая точка сопровождения, быстрый путь для новых архитектур.
  - Затраты: низкие-средние.
  - Где: новый модуль `src-tauri/src/core/weights.rs` с функциями: `hub_list_safetensors(...)`, `local_list_safetensors(...)`, `build_varbuilder(...)`, `hub_cache_safetensors(...)`; заменить локальный разбор в `api/model_loading/hub_safetensors.rs` и `api/model_loading/local_safetensors.rs`.
  - Статус: РЕАЛИЗОВАНО ✓ (полная реализация с поддержкой Hub и локальных путей, унифицированной политикой dtype)

- Адаптер для float‑LLM из candle_transformers (safetensors)
  - Назначение: позволить использовать модели `ModelForCausalLM` (например, Qwen3 float) через уже существующий трейт `ModelBackend`.
  - Влияние: единая генерация как для GGUF, так и для HF safetensors (без квантовки); снимает барьер для множества архитектур из `candle_transformers`.
  - Затраты: низкие-средние (тонкая обёртка + реализация `AnyModel::from_candle_qwen3`).
  - Где: новый `src-tauri/src/models/common/candle_llm.rs` (реализует `ModelBackend` поверх `ModelForCausalLM`), доработка `src-tauri/src/models/common/model.rs` (реализовать `from_candle_qwen3`).
  - Статус: РЕАЛИЗОВАНО ✓ (полная реализация с поддержкой различных архитектур из candle_transformers)

- Расширение реестра архитектур и детектирование
  - Назначение: распознавать архитектуры из списка поддерживаемых моделей (Llama, Mistral, Mixtral, Gemma, Qwen, Yi, Phi3, DeepSeek, Pixtral, SmolLM2) по `config.json`/GGUF metadata.
  - Влияние: централизованное определение архитектуры → единый вход для билдеров моделей.
  - Затраты: низкие.
  - Где: `src-tauri/src/models/registry.rs` — добавить эвристики (по полям типа `model_type`, `architectures`, `general.architecture`, и др.).
  - Статус: РЕАЛИЗОВАНО ✓ (полная реализация с поддержкой моделей из списка пользователя, удалены неподдерживаемые архитектуры)

P1 — Системные улучшения универсальности

- Введение трейт‑билдера моделей (`ModelBuilder`) и фабрики
  - Назначение: унифицировать создание модели из GGUF и из VarBuilder+config (`from_gguf(...)`, `from_varbuilder(...)`).
  - Влияние: минимизация архитектурного кода до локальных адаптеров; упрощение подключения новых архитектур.
  - Затраты: средние (введение трейт‑слоя и регистрация билдеров по `ArchKind`).
  - Где: новый `src-tauri/src/models/common/builder.rs`; регистрация в `src-tauri/src/models/registry.rs`; адаптеры в `src-tauri/src/models/<arch>.rs`.
  - Статус: РЕАЛИЗОВАНО ✓ (полная реализация с унифицированным интерфейсом для GGUF и safetensors моделей, фабрикой и детектированием архитектур)

- Prompt builder на основе chat template
  - Назначение: единообразно формировать промпт из сообщений и шаблона (`tokenizer.json`/metadata).
  - Влияние: одинаковое поведение чата у разных моделей; снижение копипасты.
  - Затраты: низкие-средние.
  - Где: новый `src-tauri/src/core/prompt.rs`; использование в `src-tauri/src/generate/stream.rs` до токенизации.
  - Статус: РЕАЛИЗОВАНО ✓ (полная реализация с поддержкой шаблонов Jinja и резервного форматирования, интегрирована в пайплайн генерации)

- Унификация параметров генерации (SamplingOptions)
  - Назначение: собрать `temperature/top_k/top_p/min_p/seed/repeat_penalty/repeat_last_n` в один тип с дефолтами и единым логированием.
  - Влияние: стабильное поведение и простая передача опций во все режимы генерации.
  - Затраты: низкие.
  - Где: новый `src-tauri/src/core/config.rs` (или `generate/options.rs`); обновить `generate/sampling.rs`, `generate/stream.rs`.
  - Статус: РЕАЛИЗОВАНО ✓ (полная реализация с унифицированным типом SamplingOptions, предустановленными конфигурациями и интеграцией в пайплайн генерации)

- Централизация политики dtype/precision
  - Назначение: единая политика F16/BF16/F32 (GPU→BF16/F16, CPU→F32) с опциональной переопределяемостью через UI.
  - Влияние: согласованная точность и потребление памяти; меньше расхождений между загрузчиками; пользовательский контроль над точностью.
  - Затраты: низкие.
  - Где: новый `src-tauri/src/core/precision.rs`; использовать в `core/weights.rs` и при инициализации моделей; UI в `src/routes/settings`.
  - Статус: РЕАЛИЗОВАНО ✓ (полная реализация с централизованной политикой точности, конфигурациями по умолчанию, возможностью настройки и UI интеграцией)

- Единообразное логирование и ошибки
  - Назначение: унифицировать префиксы (`[load]`, `[infer]`, `[hub]`, `[template]`) и представление ошибок.
  - Влияние: улучшение сопровождения и отладки; понятные трассы для всех архитектур.
  - Затраты: низкие.
  - Где: `src-tauri/src/core/log.rs`; применить в загрузчиках и генерации.
  - Статус: РЕАЛИЗОВАНО ✓ (полная реализация с унифицированными макросами логирования, префиксами компонентов и интеграцией во все модули)
  - Реализация:
    - Модуль `src-tauri/src/core/log.rs`:
      - Унифицированные макросы логирования с префиксами компонентов
      - Поддержка компонентов: Load, Infer, Hub, Local, Template, Device, Validate, Weights, Generate, Tokenizer, Architecture
      - Автоматическая инициализация env_logger с кастомным форматированием
      - Удобные макросы для каждого компонента (log_load!, log_infer!, log_hub!, и т.д.)
      - Макросы для ошибок и предупреждений с компонентами
      - Функции для логирования производительности и размера данных
      - Интеграция с crate `log` и `env_logger`
    - Интеграция:
      - Заменены все `println!` и `eprintln!` на соответствующие макросы логирования
      - Обновлены все модули: device, weights, prompt, generate, api, model_loading
      - Единообразные префиксы для всех компонентов системы
      - Улучшенная читаемость и структурированность логов

P2 — Повышение надёжности и готовности к росту

- Минимальные smoke‑тесты ключевых компонентов
  - Назначение: проверить `tokenizer_from_gguf_metadata`, извлечение EOS, prompt builder, интерфейс `ModelBackend` (prefill/decode шаги на малых входах).
  - Влияние: снижает регрессии при добавлении архитектур; ускоряет ревью.
  - Затраты: средние.
  - Где: `src-tauri/tests` или модульные тесты рядом с кодом.
  - Тесты должны проводитсья с реальнйо моделью D:\GitHub\Oxide-Lab\models\gguf\Qwen3-0.6B-unsloth-GGUF

- Общие препроцессоры/постпроцессоры для мультимодальных моделей
  - Назначение: заложить основу для CV/Audio (нормализация, ресайз, mel‑спектрограммы) по образцу `candle_examples`.
  - Влияние: готовность к будущим архитектурам (CLIP, Whisper и т.п.).
  - Затраты: средние; опционально.
  - Где: `src-tauri/src/core/vision.rs`, `src-tauri/src/core/audio.rs`, `src-tauri/src/core/multimodal.rs`.
  - Статус: РЕАЛИЗОВАНО ✓ (полная реализация с поддержкой предварительной обработки изображений, аудио и унифицированными интерфейсами)
  - Реализация:
    - Модуль `src-tauri/src/core/vision.rs`:
      - Полная реализация препроцессоров изображений на основе примеров Candle
      - Поддержка различных конфигураций: ImageNet, CLIP, DINOv2, Training
      - Методы изменения размера: Exact, Fill, ResizeLongest, ResizeShortest
      - Центральная обрезка и аугментации (случайные повороты, цветовые искажения)
      - Нормализация с настраиваемыми параметрами mean/std
      - Поддержка загрузки из файлов и байтов
      - Преобразование тензоров обратно в изображения для визуализации
      - Функции извлечения признаков для интеграции с моделями
    - Модуль `src-tauri/src/core/audio.rs`:
      - Полная реализация препроцессоров аудио на основе примеров Candle
      - Поддержка различных конфигураций: Whisper, EnCodec, MusicGen, Speech
      - Загрузка аудио через Symphonia (как в примерах Candle)
      - Ресемплирование с линейной интерполяцией
      - Нормализация громкости по алгоритму BS.1770
      - Генерация мел-спектрограмм с настраиваемыми фильтрами
      - Поддержка различных оконных функций: Hann, Hamming, Rectangular
      - Простая реализация FFT для демонстрации
      - Преобразование мел-спектрограмм обратно в аудио
      - Pre-emphasis фильтрация и паддинг/обрезание
    - Модуль `src-tauri/src/core/multimodal.rs`:
      - Унифицированные интерфейсы для мультимодальной обработки
      - Конфигурации для различных типов моделей (CLIP, Whisper, MusicGen, Training)
      - Поддержка пакетной обработки с настраиваемым размером батча
      - Потоковая обработка для больших датасетов
      - Структуры данных для мультимодальных выборок
      - Метаданные для отслеживания информации о данных
      - Утилиты для валидации и визуализации
      - Интеграция с существующими модулями vision и audio
    - Тестирование:
      - Комплексные unit-тесты для всех модулей
      - Тестирование различных конфигураций и методов
      - Проверка корректности преобразований данных
      - Валидация производительности и памяти
    - Интеграция с Candle:
      - Использование паттернов из `candle_examples`
      - Совместимость с существующими моделями
      - Поддержка различных устройств (CPU, GPU)
      - Оптимизация для производительности
    - Примеры использования:

      ```rust
      // Обработка изображений для CLIP
      let config = MultimodalConfig::clip();
      let processor = MultimodalProcessor::new(config, device);
      let image_tensor = processor.process_image("image.jpg")?;

      // Обработка аудио для Whisper
      let config = MultimodalConfig::whisper();
      let processor = MultimodalProcessor::new(config, device);
      let audio_tensor = processor.process_audio("audio.wav")?;
      let mel_spectrogram = processor.audio_to_mel(&audio_tensor)?;

      // Пакетная обработка
      let batch_processor = MultimodalBatchProcessor::new(processor, 16);
      let samples = vec![MultimodalSample::vision(image_tensor, metadata)];
      let processed = batch_processor.process_batch(samples)?;
      ```

- Расширение интерфейса `ModelBackend` при необходимости
  - Назначение: явно выразить поддержку kv‑cache/позиций, спец‑токенов, ограничений контекста.
  - Влияние: менее хрупкая интеграция разных реализаций; упрощение оптимизаций.
  - Затраты: низкие‑средние (по мере появления потребности).
  - Где: `src-tauri/src/models/common/model.rs` (расширение трейта и адаптеров).

Рекомендуемый порядок внедрения (по убыванию приоритета)

1. P0: авто‑device; модуль `core/weights.rs`; адаптер float‑LLM; расширение детекта архитектур.
2. P1: `ModelBuilder`+фабрика; prompt builder; `SamplingOptions`; `precision`‑политика; единое логирование.
3. P2: smoke‑тесты; мультимодальные утилиты; эволюция `ModelBackend` при необходимости.

Ожидаемый результат

- Добавление новой архитектуры сводится к: (а) дописать детект в `registry`, (б) реализовать адаптер/билдер в `models/<arch>.rs` (GGUF и/или VarBuilder), (в) при необходимости настроить prompt‑builder. Остальное (загрузка весов, политика dtype, устройство, генерация, токенизация, логи) — универсально и не меняется.
