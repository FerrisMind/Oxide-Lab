---
description: Candle testing, validation and quality assurance best practices
globs: *.rs,Cargo.toml
alwaysApply: false
---

# Candle Testing & Validation

## Настройка тестового окружения

### Базовые зависимости для тестирования

```toml
[dev-dependencies]
criterion = { version = "0.7", features = ["html_reports"] }
proptest = "1"
approx = "0.5"
tempfile = "3"
mockall = "0.13"
tokio-test = "0.4"

# Для property-based тестирования
proptest-derive = "0.6"

# Для интеграционных тестов
reqwest = { version = "0.12", features = ["json"] }
```

### Структура тестов

```
tests/
├── integration/           # Интеграционные тесты
│   ├── model_loading.rs
│   ├── training.rs
│   └── inference.rs
├── unit/                  # Unit тесты
│   ├── tensor_ops.rs
│   ├── layers.rs
│   └── optimizers.rs
├── property/              # Property-based тесты
│   ├── tensor_properties.rs
│   └── model_properties.rs
└── benchmarks/            # Бенчмарки
    ├── tensor_benchmarks.rs
    └── model_benchmarks.rs
```

## Unit тестирование

### Тестирование операций с тензорами

```rust
#[cfg(test)]
mod tensor_tests {
    use super::*;
    use candle_core::{Tensor, Device, DType};
    use approx::assert_abs_diff_eq;

    #[test]
    fn test_tensor_creation() {
        let device = Device::Cpu;
        let tensor = Tensor::zeros((2, 3), DType::F32, &device).unwrap();

        assert_eq!(tensor.shape(), &[2, 3]);
        assert_eq!(tensor.dtype(), DType::F32);
        assert_eq!(tensor.device(), &device);
    }

    #[test]
    fn test_tensor_operations() {
        let device = Device::Cpu;
        let a = Tensor::ones((2, 2), DType::F32, &device).unwrap();
        let b = Tensor::ones((2, 2), DType::F32, &device).unwrap();

        let sum = (&a + &b).unwrap();
        let expected = Tensor::from_slice(&[2.0, 2.0, 2.0, 2.0], (2, 2), &device).unwrap();

        assert_tensor_eq(&sum, &expected, 1e-6);
    }

    #[test]
    fn test_matrix_multiplication() {
        let device = Device::Cpu;
        let a = Tensor::from_slice(&[1.0, 2.0, 3.0, 4.0], (2, 2), &device).unwrap();
        let b = Tensor::from_slice(&[2.0, 0.0, 1.0, 2.0], (2, 2), &device).unwrap();

        let result = a.matmul(&b).unwrap();
        let expected = Tensor::from_slice(&[4.0, 4.0, 10.0, 8.0], (2, 2), &device).unwrap();

        assert_tensor_eq(&result, &expected, 1e-6);
    }

    /// Вспомогательная функция для сравнения тензоров
    fn assert_tensor_eq(a: &Tensor, b: &Tensor, tolerance: f32) {
        assert_eq!(a.shape(), b.shape());
        assert_eq!(a.dtype(), b.dtype());

        let a_data: Vec<f32> = a.to_vec1().unwrap();
        let b_data: Vec<f32> = b.to_vec1().unwrap();

        for (a_val, b_val) in a_data.iter().zip(b_data.iter()) {
            assert_abs_diff_eq!(a_val, b_val, epsilon = tolerance);
        }
    }
}
```

### Тестирование слоев нейронных сетей

```rust
#[cfg(test)]
mod layer_tests {
    use super::*;
    use candle_nn::{Linear, LayerNorm, Dropout};
    use candle_core::{Tensor, Device, DType};

    #[test]
    fn test_linear_layer() {
        let device = Device::Cpu;
        let input_size = 10;
        let output_size = 5;

        let linear = Linear::new(input_size, output_size, &device).unwrap();
        let input = Tensor::randn(0f32, 1f32, (batch_size, input_size), &device).unwrap();

        let output = linear.forward(&input).unwrap();

        assert_eq!(output.shape(), &[batch_size, output_size]);
        assert_eq!(output.dtype(), DType::F32);
    }

    #[test]
    fn test_layer_normalization() {
        let device = Device::Cpu;
        let hidden_size = 768;

        let layer_norm = LayerNorm::new(hidden_size, 1e-5, &device).unwrap();
        let input = Tensor::randn(0f32, 1f32, (batch_size, hidden_size), &device).unwrap();

        let output = layer_norm.forward(&input).unwrap();

        // Проверяем, что нормализация работает
        let mean = output.mean_all().unwrap().to_scalar::<f32>().unwrap();
        let std = output.var_all().unwrap().sqrt().unwrap().to_scalar::<f32>().unwrap();

        assert_abs_diff_eq!(mean, 0.0, epsilon = 1e-3);
        assert_abs_diff_eq!(std, 1.0, epsilon = 1e-3);
    }

    #[test]
    fn test_dropout_training_mode() {
        let device = Device::Cpu;
        let dropout_rate = 0.5;

        let mut dropout = Dropout::new(dropout_rate);
        let input = Tensor::ones((10, 10), DType::F32, &device).unwrap();

        // В режиме обучения
        dropout.set_training(true);
        let output = dropout.forward(&input).unwrap();

        // Проверяем, что некоторые элементы занулены
        let output_data: Vec<f32> = output.to_vec1().unwrap();
        let zero_count = output_data.iter().filter(|&&x| x == 0.0).count();
        assert!(zero_count > 0, "Dropout должен занулять некоторые элементы");
    }

    #[test]
    fn test_dropout_inference_mode() {
        let device = Device::Cpu;
        let dropout_rate = 0.5;

        let mut dropout = Dropout::new(dropout_rate);
        let input = Tensor::ones((10, 10), DType::F32, &device).unwrap();

        // В режиме инференса
        dropout.set_training(false);
        let output = dropout.forward(&input).unwrap();

        // Проверяем, что все элементы сохранены
        assert_tensor_eq(&output, &input, 1e-6);
    }
}
```

### Тестирование оптимизаторов

```rust
#[cfg(test)]
mod optimizer_tests {
    use super::*;
    use candle_core::{Tensor, Device, DType};

    #[test]
    fn test_sgd_optimizer() {
        let device = Device::Cpu;
        let learning_rate = 0.01;
        let momentum = 0.9;

        let mut optimizer = SGD::new(learning_rate, momentum);

        // Создаем тестовые параметры и градиенты
        let mut param = Tensor::ones((2, 2), DType::F32, &device).unwrap();
        let gradient = Tensor::ones((2, 2), DType::F32, &device).unwrap();

        let initial_param = param.clone();

        // Выполняем шаг оптимизации
        optimizer.step(&mut [param.clone()], &[gradient]).unwrap();

        // Проверяем, что параметры изменились
        assert!(!tensors_equal(&param, &initial_param));

        // Проверяем правильность обновления
        let expected = &initial_param - &gradient * learning_rate;
        assert_tensor_eq(&param, &expected, 1e-6);
    }

    #[test]
    fn test_adam_optimizer() {
        let device = Device::Cpu;
        let learning_rate = 0.001;

        let mut optimizer = Adam::new(learning_rate);

        let mut param = Tensor::ones((2, 2), DType::F32, &device).unwrap();
        let gradient = Tensor::ones((2, 2), DType::F32, &device).unwrap();

        // Выполняем несколько шагов
        for _ in 0..10 {
            optimizer.step(&mut [param.clone()], &[gradient.clone()]).unwrap();
        }

        // Проверяем, что параметры изменились
        let initial_param = Tensor::ones((2, 2), DType::F32, &device).unwrap();
        assert!(!tensors_equal(&param, &initial_param));
    }

    fn tensors_equal(a: &Tensor, b: &Tensor) -> bool {
        if a.shape() != b.shape() || a.dtype() != b.dtype() {
            return false;
        }

        let a_data: Vec<f32> = a.to_vec1().unwrap();
        let b_data: Vec<f32> = b.to_vec1().unwrap();

        a_data.iter().zip(b_data.iter()).all(|(a, b)| (a - b).abs() < 1e-6)
    }
}
```

## Property-based тестирование

### Тестирование свойств тензоров

```rust
use proptest::prelude::*;

proptest! {
    #[test]
    fn test_tensor_addition_commutativity(
        shape in (1..10usize).prop_flat_map(|s| (s, s)),
        values1 in prop::collection::vec(-10.0f32..10.0, 1..100),
        values2 in prop::collection::vec(-10.0f32..10.0, 1..100)
    ) {
        let device = Device::Cpu;
        let size = shape.0 * shape.1;

        if values1.len() >= size && values2.len() >= size {
            let tensor1 = Tensor::from_slice(&values1[..size], shape, &device).unwrap();
            let tensor2 = Tensor::from_slice(&values2[..size], shape, &device).unwrap();

            let result1 = (&tensor1 + &tensor2).unwrap();
            let result2 = (&tensor2 + &tensor1).unwrap();

            assert_tensor_eq(&result1, &result2, 1e-6);
        }
    }

    #[test]
    fn test_matrix_multiplication_associativity(
        m in 1..10usize,
        n in 1..10usize,
        k in 1..10usize,
        values_a in prop::collection::vec(-5.0f32..5.0, 1..100),
        values_b in prop::collection::vec(-5.0f32..5.0, 1..100),
        values_c in prop::collection::vec(-5.0f32..5.0, 1..100)
    ) {
        let device = Device::Cpu;

        if values_a.len() >= m * n && values_b.len() >= n * k && values_c.len() >= k * m {
            let a = Tensor::from_slice(&values_a[..m*n], (m, n), &device).unwrap();
            let b = Tensor::from_slice(&values_b[..n*k], (n, k), &device).unwrap();
            let c = Tensor::from_slice(&values_c[..k*m], (k, m), &device).unwrap();

            // (A * B) * C = A * (B * C)
            let ab = a.matmul(&b).unwrap();
            let abc1 = ab.matmul(&c).unwrap();

            let bc = b.matmul(&c).unwrap();
            let abc2 = a.matmul(&bc).unwrap();

            assert_tensor_eq(&abc1, &abc2, 1e-4);
        }
    }

    #[test]
    fn test_tensor_reshape_preserves_elements(
        original_shape in (1..10usize).prop_flat_map(|s| (s, s)),
        new_shape in (1..10usize).prop_flat_map(|s| (s, s)),
        values in prop::collection::vec(-10.0f32..10.0, 1..100)
    ) {
        let device = Device::Cpu;
        let original_size = original_shape.0 * original_shape.1;
        let new_size = new_shape.0 * new_shape.1;

        if values.len() >= original_size && original_size == new_size {
            let tensor = Tensor::from_slice(&values[..original_size], original_shape, &device).unwrap();
            let reshaped = tensor.reshape(new_shape).unwrap();

            // Проверяем, что сумма элементов сохранилась
            let original_sum = tensor.sum_all().unwrap().to_scalar::<f32>().unwrap();
            let reshaped_sum = reshaped.sum_all().unwrap().to_scalar::<f32>().unwrap();

            assert_abs_diff_eq!(original_sum, reshaped_sum, epsilon = 1e-6);
        }
    }
}
```

## Интеграционные тесты

### Тестирование загрузки моделей

```rust
#[cfg(test)]
mod integration_tests {
    use super::*;
    use tempfile::TempDir;

    #[tokio::test]
    async fn test_model_loading_from_hub() {
        let device = Device::Cpu;

        // Тестируем загрузку небольшой модели
        let model_id = "distilbert-base-uncased";

        let model = load_llama_model(model_id, &device).await;

        match model {
            Ok(m) => {
                assert!(m.num_parameters() > 0);
                assert_eq!(m.device(), &device);
            }
            Err(e) => {
                // Если модель недоступна, это не ошибка теста
                println!("Модель {} недоступна: {}", model_id, e);
            }
        }
    }

    #[test]
    fn test_model_save_and_load() {
        let device = Device::Cpu;
        let temp_dir = TempDir::new().unwrap();
        let model_path = temp_dir.path().join("test_model.safetensors");

        // Создаем тестовую модель
        let config = TransformerConfig::default();
        let original_model = Transformer::new(config.clone(), &device).unwrap();

        // Сохраняем модель
        save_model_safetensors(&original_model, model_path.to_str().unwrap()).unwrap();

        // Загружаем модель
        let loaded_model = load_model_safetensors::<Transformer>(
            model_path.to_str().unwrap(),
            &device
        ).unwrap();

        // Проверяем, что модели эквивалентны
        assert_eq!(original_model.num_parameters(), loaded_model.num_parameters());

        // Тестируем forward pass
        let test_input = Tensor::randn(0f32, 1f32, (1, 10), &device).unwrap();
        let original_output = original_model.forward(&test_input).unwrap();
        let loaded_output = loaded_model.forward(&test_input).unwrap();

        assert_tensor_eq(&original_output, &loaded_output, 1e-6);
    }

    #[test]
    fn test_end_to_end_training() {
        let device = Device::Cpu;

        // Создаем простую модель
        let config = TransformerConfig {
            vocab_size: 1000,
            hidden_size: 64,
            num_attention_heads: 4,
            num_hidden_layers: 2,
            intermediate_size: 128,
            max_position_embeddings: 512,
            dropout_prob: 0.1,
        };

        let mut model = Transformer::new(config, &device).unwrap();
        let mut optimizer = Adam::new(0.001);

        // Создаем тестовые данные
        let batch_size = 4;
        let seq_len = 10;
        let input_ids = Tensor::randn(0f32, 1f32, (batch_size, seq_len), &device).unwrap();
        let labels = Tensor::randn(0f32, 1f32, (batch_size, seq_len), &device).unwrap();

        // Выполняем несколько шагов обучения
        for _ in 0..5 {
            let logits = model.forward(&input_ids).unwrap();
            let loss = compute_loss(&logits, &labels).unwrap();

            // Вычисляем градиенты (упрощенная версия)
            let gradients = compute_gradients(&loss, &model).unwrap();

            // Обновляем параметры
            let mut params = model.parameters();
            optimizer.step(&mut params, &gradients).unwrap();
        }

        // Проверяем, что модель все еще работает
        let final_output = model.forward(&input_ids).unwrap();
        assert_eq!(final_output.shape(), &[batch_size, seq_len, config.vocab_size]);
    }
}
```

## Бенчмарки производительности

### Бенчмарки операций с тензорами

```rust
use criterion::{criterion_group, criterion_main, Criterion, BenchmarkId};

fn benchmark_tensor_operations(c: &mut Criterion) {
    let device = Device::Cpu;

    let mut group = c.benchmark_group("tensor_operations");

    for size in [100, 500, 1000, 2000].iter() {
        let tensor_a = Tensor::randn(0f32, 1f32, (*size, *size), &device).unwrap();
        let tensor_b = Tensor::randn(0f32, 1f32, (*size, *size), &device).unwrap();

        group.bench_with_input(BenchmarkId::new("matmul", size), size, |b, _| {
            b.iter(|| {
                tensor_a.matmul(&tensor_b).unwrap()
            });
        });

        group.bench_with_input(BenchmarkId::new("addition", size), size, |b, _| {
            b.iter(|| {
                (&tensor_a + &tensor_b).unwrap()
            });
        });

        group.bench_with_input(BenchmarkId::new("relu", size), size, |b, _| {
            b.iter(|| {
                tensor_a.relu().unwrap()
            });
        });
    }

    group.finish();
}

fn benchmark_model_forward(c: &mut Criterion) {
    let device = Device::Cpu;
    let config = TransformerConfig::default();
    let model = Transformer::new(config, &device).unwrap();

    let mut group = c.benchmark_group("model_forward");

    for batch_size in [1, 4, 8, 16].iter() {
        let input = Tensor::randn(0f32, 1f32, (*batch_size, 512), &device).unwrap();

        group.bench_with_input(BenchmarkId::new("transformer", batch_size), batch_size, |b, _| {
            b.iter(|| {
                model.forward(&input).unwrap()
            });
        });
    }

    group.finish();
}

criterion_group!(benches, benchmark_tensor_operations, benchmark_model_forward);
criterion_main!(benches);
```

## Тестирование на GPU

### Условное тестирование GPU

```rust
#[cfg(test)]
mod gpu_tests {
    use super::*;

    #[test]
    #[cfg(feature = "cuda")]
    fn test_cuda_operations() {
        let device = Device::new_cuda(0).unwrap_or_else(|_| {
            println!("CUDA недоступна, пропускаем тест");
            return Device::Cpu;
        });

        let tensor = Tensor::randn(0f32, 1f32, (100, 100), &device).unwrap();
        let result = tensor.matmul(&tensor).unwrap();

        assert_eq!(result.shape(), &[100, 100]);
    }

    #[test]
    fn test_device_agnostic_operations() {
        let devices = vec![Device::Cpu];

        #[cfg(feature = "cuda")]
        if let Ok(cuda_device) = Device::new_cuda(0) {
            devices.push(cuda_device);
        }

        for device in devices {
            let tensor = Tensor::ones((2, 2), DType::F32, &device).unwrap();
            let result = tensor.matmul(&tensor).unwrap();

            assert_eq!(result.shape(), &[2, 2]);
        }
    }
}
```

## Моки и тестовые двойники

### Создание моков для тестирования

```rust
use mockall::*;

#[automock]
pub trait ModelTrait {
    fn forward(&self, input: &Tensor) -> Result<Tensor>;
    fn num_parameters(&self) -> usize;
    fn device(&self) -> &Device;
}

#[cfg(test)]
mod mock_tests {
    use super::*;

    #[test]
    fn test_with_mock_model() {
        let mut mock_model = MockModelTrait::new();

        // Настраиваем ожидания
        mock_model
            .expect_forward()
            .times(1)
            .returning(|_| {
                let device = Device::Cpu;
                Tensor::ones((1, 10), DType::F32, &device)
            });

        mock_model
            .expect_num_parameters()
            .return_const(1000);

        mock_model
            .expect_device()
            .return_const(Device::Cpu);

        // Тестируем с моком
        let input = Tensor::randn(0f32, 1f32, (1, 5), &Device::Cpu).unwrap();
        let output = mock_model.forward(&input).unwrap();

        assert_eq!(output.shape(), &[1, 10]);
        assert_eq!(mock_model.num_parameters(), 1000);
    }
}
```

## Валидация численной точности

### Сравнение с reference реализациями

```rust
#[cfg(test)]
mod numerical_validation {
    use super::*;

    #[test]
    fn test_attention_against_reference() {
        let device = Device::Cpu;

        // Создаем тестовые данные
        let batch_size = 2;
        let seq_len = 4;
        let hidden_size = 8;

        let query = Tensor::randn(0f32, 1f32, (batch_size, seq_len, hidden_size), &device).unwrap();
        let key = Tensor::randn(0f32, 1f32, (batch_size, seq_len, hidden_size), &device).unwrap();
        let value = Tensor::randn(0f32, 1f32, (batch_size, seq_len, hidden_size), &device).unwrap();

        // Наша реализация
        let our_output = multi_head_attention(&query, &key, &value).unwrap();

        // Reference реализация (упрощенная)
        let ref_output = reference_attention(&query, &key, &value).unwrap();

        // Сравниваем результаты
        assert_tensor_eq(&our_output, &ref_output, 1e-4);
    }

    #[test]
    fn test_layer_norm_against_reference() {
        let device = Device::Cpu;
        let hidden_size = 64;

        let input = Tensor::randn(0f32, 1f32, (4, hidden_size), &device).unwrap();

        // Наша реализация
        let layer_norm = LayerNorm::new(hidden_size, 1e-5, &device).unwrap();
        let our_output = layer_norm.forward(&input).unwrap();

        // Reference реализация
        let ref_output = reference_layer_norm(&input).unwrap();

        assert_tensor_eq(&our_output, &ref_output, 1e-5);
    }

    fn reference_attention(query: &Tensor, key: &Tensor, value: &Tensor) -> Result<Tensor> {
        // Упрощенная reference реализация attention
        let scores = query.matmul(&key.transpose(-2, -1)?)?;
        let attn_weights = scores.softmax(-1)?;
        let output = attn_weights.matmul(value)?;
        Ok(output)
    }

    fn reference_layer_norm(input: &Tensor) -> Result<Tensor> {
        let mean = input.mean_all()?;
        let var = input.var_all()?;
        let normalized = (input - &mean) / (var.sqrt()? + 1e-5)?;
        Ok(normalized)
    }
}
```

## Тестирование градиентов

### Проверка градиентов через finite differences

```rust
#[cfg(test)]
mod gradient_tests {
    use super::*;

    #[test]
    fn test_gradient_computation() {
        let device = Device::Cpu;
        let epsilon = 1e-5;

        // Создаем простую функцию
        let x = Tensor::new(&[2.0f32], &device).unwrap();
        let x_clone = x.clone();

        // Функция: f(x) = x^2
        let y = x.powf(2.0).unwrap();

        // Вычисляем градиент
        let grad = compute_gradient(&y, &x_clone).unwrap();

        // Аналитический градиент: df/dx = 2x = 4.0
        let analytical_grad = x_clone * 2.0;

        assert_tensor_eq(&grad, &analytical_grad, 1e-6);
    }

    #[test]
    fn test_finite_difference_gradient() {
        let device = Device::Cpu;
        let epsilon = 1e-5;

        let x_val = 3.0f32;
        let x = Tensor::new(&[x_val], &device).unwrap();

        // Функция: f(x) = x^3 + 2x^2
        let y = x.powf(3.0).unwrap() + x.powf(2.0).unwrap() * 2.0;

        // Вычисляем градиент через finite differences
        let x_plus = Tensor::new(&[x_val + epsilon], &device).unwrap();
        let x_minus = Tensor::new(&[x_val - epsilon], &device).unwrap();

        let y_plus = x_plus.powf(3.0).unwrap() + x_plus.powf(2.0).unwrap() * 2.0;
        let y_minus = x_minus.powf(3.0).unwrap() + x_minus.powf(2.0).unwrap() * 2.0;

        let finite_diff_grad = (&y_plus - &y_minus).unwrap() / (2.0 * epsilon);

        // Аналитический градиент: df/dx = 3x^2 + 4x = 3*9 + 4*3 = 39
        let analytical_grad = Tensor::new(&[39.0f32], &device).unwrap();

        assert_tensor_eq(&finite_diff_grad, &analytical_grad, 1e-4);
    }

    fn compute_gradient(output: &Tensor, input: &Tensor) -> Result<Tensor> {
        // Упрощенная реализация вычисления градиента
        // В реальности здесь должен быть backward pass
        Ok(Tensor::ones_like(input)?)
    }
}
```

## Лучшие практики тестирования

### 1. Используйте детерминированные тесты

```rust
#[test]
fn test_deterministic_operations() {
    // Устанавливаем детерминированный seed
    let device = Device::Cpu;

    // Используем фиксированные значения вместо случайных
    let tensor = Tensor::from_slice(&[1.0, 2.0, 3.0, 4.0], (2, 2), &device).unwrap();
    let result = tensor.matmul(&tensor).unwrap();

    let expected = Tensor::from_slice(&[7.0, 10.0, 15.0, 22.0], (2, 2), &device).unwrap();
    assert_tensor_eq(&result, &expected, 1e-6);
}
```

### 2. Тестируйте edge cases

```rust
#[test]
fn test_edge_cases() {
    let device = Device::Cpu;

    // Тест с нулевыми тензорами
    let zero_tensor = Tensor::zeros((0, 0), DType::F32, &device).unwrap();
    assert_eq!(zero_tensor.shape(), &[0, 0]);

    // Тест с очень маленькими значениями
    let small_tensor = Tensor::from_slice(&[1e-10f32], &device).unwrap();
    let result = small_tensor.sqrt().unwrap();
    assert!(result.to_scalar::<f32>().unwrap() > 0.0);

    // Тест с очень большими значениями
    let large_tensor = Tensor::from_slice(&[1e10f32], &device).unwrap();
    let result = large_tensor.log().unwrap();
    assert!(result.to_scalar::<f32>().unwrap().is_finite());
}
```

### 3. Группируйте связанные тесты

```rust
#[cfg(test)]
mod transformer_tests {
    use super::*;

    #[test]
    fn test_transformer_creation() {
        // Тесты создания
    }

    #[test]
    fn test_transformer_forward() {
        // Тесты forward pass
    }

    #[test]
    fn test_transformer_attention() {
        // Тесты attention механизма
    }

    #[test]
    fn test_transformer_training() {
        // Тесты обучения
    }
}
```

### 4. Используйте параметризованные тесты

```rust
#[test]
fn test_different_batch_sizes() {
    let device = Device::Cpu;
    let batch_sizes = vec![1, 4, 8, 16, 32];

    for batch_size in batch_sizes {
        let input = Tensor::randn(0f32, 1f32, (batch_size, 10), &device).unwrap();
        let model = create_test_model(&device).unwrap();

        let output = model.forward(&input).unwrap();
        assert_eq!(output.dim(0), batch_size);
    }
}
```

Следуйте этим практикам для создания надежных и comprehensive тестов для ваших Candle приложений.
