</p>
<p align="left">
  <a href="README.md"><img src="https://img.shields.io/badge/English-232323" alt="English"></a>
  <a href="README.RU.md"><img src="https://img.shields.io/badge/–†—É—Å—Å–∫–∏–π-232323" alt="–†—É—Å—Å–∫–∏–π"></a>
  <a href="README.PT_BR.md"><img src="https://img.shields.io/badge/Portugu√™s_BR-3ABF7A" alt="Portugu√™s"></a>
</p>

---

<p align="center">
  <img src="https://raw.githubusercontent.com/FerrisMind/Oxide-Lab/main/.github/assets/logo.svg" alt="Oxide Lab Logo" width="512" height="512">


<p align="center">
  Aplicativo desktop privado de chat com IA com suporte a LLMs locais.<br>
  Toda a infer√™ncia acontece na sua m√°quina ‚Äî sem nuvem, sem compartilhamento de dados.
</p>

<p align="center">
  <a href="https://github.com/FerrisMind/Oxide-Lab/stargazers"><img src="https://img.shields.io/github/stars/FerrisMind/Oxide-Lab?logo=github" alt="GitHub Stars"></a>
  <a href="https://github.com/tauri-apps/awesome-tauri"><img src="https://img.shields.io/badge/Awesome-Tauri-24C8D8?logo=tauri" alt="Awesome Tauri"></a>
  <a href="https://github.com/TheComputerM/awesome-svelte"><img src="https://img.shields.io/badge/Awesome-Svelte-FF3E00?logo=svelte" alt="Awesome Svelte"></a>
</p>

<h1 align="center"></h1>

<p align="center">
  <img src="https://raw.githubusercontent.com/FerrisMind/Oxide-Lab/main/.github/assets/screenshots/chat-dark.png" alt="Oxide Lab Chat Interface" width="900">
</p>

## üìö √çndice

- [O que √© isso?](#-o-que-√©-isso)
- [Demo](#-demo)
- [Principais Recursos](#-principais-recursos)
- [Instala√ß√£o e Configura√ß√£o](#Ô∏è-instala√ß√£o-e-configura√ß√£o)
- [Como Come√ßar a Usar](#-como-come√ßar-a-usar)
- [Requisitos do Sistema](#Ô∏è-requisitos-do-sistema)
- [Modelos Suportados](#-modelos-suportados)
- [Privacidade e Seguran√ßa](#Ô∏è-privacidade-e-seguran√ßa)
- [Agradecimentos](#-agradecimentos)
- [Licen√ßa](#-licen√ßa)

## ‚ú® O que √© isso?

Oxide Lab √© um aplicativo desktop nativo para executar modelos de linguagem grandes localmente. Constru√≠do com Rust e Tauri v2, oferece uma interface de chat r√°pida e privada sem necessidade de conex√£o com a internet ou servi√ßos de API externos.

## üé¨ Demo

https://github.com/user-attachments/assets/0b9c8ff9-7793-4108-8b62-b0800cbd855e

https://github.com/user-attachments/assets/27c1f544-69e0-4a91-8fa5-4c21d67cb7c7

https://github.com/user-attachments/assets/ce5337d5-3e63-4263-b6a7-56e6847bbc71

## üöÄ Principais Recursos

- Infer√™ncia 100% local ‚Äî seus dados nunca saem da sua m√°quina
- Suporte a m√∫ltiplas arquiteturas: Llama, Qwen2, Qwen2.5, Qwen3, Qwen3 MoE, Mistral, Mixtral, DeepSeek, Yi, SmolLM2
- Formatos de modelo GGUF e SafeTensors
- Acelera√ß√£o de hardware: CPU, CUDA (NVIDIA), Metal (Apple Silicon), Intel MKL, Apple Accelerate
- Gera√ß√£o de texto em streaming
- Interface multil√≠ngue: ingl√™s, russo, portugu√™s brasileiro
- Interface moderna constru√≠da com Svelte 5 e Tailwind CSS

## üõ†Ô∏è Instala√ß√£o e Configura√ß√£o

### Pr√©-requisitos

- Node.js (para build do frontend)
- Rust toolchain (para o backend)
- Para CUDA: GPU NVIDIA com CUDA toolkit
- Para Metal: macOS com Apple Silicon

### Desenvolvimento

```bash
# Instalar depend√™ncias
npm install

# Executar com backend CPU
npm run tauri:dev:cpu

# Executar com backend CUDA (GPU NVIDIA)
npm run tauri:dev:cuda

# Desenvolvimento com detec√ß√£o de plataforma
npm run app:dev
```

### Build

```bash
# Build com backend CPU
npm run tauri:build:cpu

# Build com backend CUDA
npm run tauri:build:cuda
```

### Verifica√ß√µes de Qualidade

```bash
npm run lint          # ESLint
npm run lint:fix      # ESLint com corre√ß√£o autom√°tica
npm run check         # Verifica√ß√£o de tipos Svelte
npm run format        # Formata√ß√£o Prettier
npm run test          # Testes Vitest
```

### Comandos espec√≠ficos do Rust (a partir de src-tauri/)

```bash
cargo clippy          # Linting
cargo test            # Testes unit√°rios
cargo audit           # Auditoria de seguran√ßa
```

## üìñ Como Come√ßar a Usar

1. Compile ou baixe o aplicativo
2. Baixe um modelo compat√≠vel em formato GGUF ou SafeTensors (por exemplo, do Hugging Face)
3. Inicie o Oxide Lab
4. Carregue seu modelo atrav√©s da interface
5. Comece a conversar

## üñ•Ô∏è Requisitos do Sistema

- Windows, macOS ou Linux
- M√≠nimo 8 GB de RAM (16+ GB recomendado para modelos maiores)
- Para acelera√ß√£o GPU:
  - NVIDIA: GPU compat√≠vel com CUDA
  - Apple: chip M1/M2/M3 (Metal)
  - Intel: CPU com suporte MKL

## ü§ñ Modelos Suportados

Arquiteturas com suporte completo:
- Llama (1, 2, 3, 4), Mistral, Mixtral, DeepSeek, Yi, SmolLM2, CodeLlama
- Qwen2, Qwen2.5, Qwen2 MoE
- Qwen3, Qwen3 MoE

Formatos:
- GGUF (modelos quantizados)
- SafeTensors

## üõ°Ô∏è Privacidade e Seguran√ßa

- Todo o processamento acontece localmente no seu dispositivo
- Sem telemetria ou coleta de dados
- Conex√£o com a internet n√£o √© necess√°ria para infer√™ncia
- Content Security Policy (CSP) aplicada

## üôè Agradecimentos

Este projeto √© constru√≠do sobre excelentes trabalhos open-source:

- [Candle](https://github.com/huggingface/candle) ‚Äî Framework ML para Rust (HuggingFace)
- [Tauri](https://tauri.app/) ‚Äî Framework para aplicativos desktop
- [Svelte](https://svelte.dev/) ‚Äî Framework frontend
- [Tokenizers](https://github.com/huggingface/tokenizers) ‚Äî Tokeniza√ß√£o r√°pida (HuggingFace)

Veja [THIRD_PARTY_LICENSES.md](THIRD_PARTY_LICENSES.md) para atribui√ß√£o completa de depend√™ncias.

## üìÑ Licen√ßa

Apache-2.0 ‚Äî veja [LICENSE](LICENSE)

Copyright (c) 2025 FerrisMind

---

*Tradu√ß√£o: Talita Maia Sousa*
